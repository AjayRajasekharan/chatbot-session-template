import streamlit as st
from transformers import pipeline

st.set_page_config(page_title="LLM Chatbot (Session 2)", page_icon="ðŸ¤–")

@st.cache_resource
def load_model(model_name: str = "google/flan-t5-small"):
    # text2text works well for Q&A / instruction style
    return pipeline("text2text-generation", model=model_name)

st.title("ðŸ¤– Simple LLM Chatbot (Hugging Face, free & open)")

with st.sidebar:
    model_choice = st.selectbox(
        "Choose a model",
        ["google/flan-t5-small", "distilgpt2"],
        help="flan-t5-small is better for Q&A; distilgpt2 is a tiny text generator."
    )
    max_new_tokens = st.slider("Max new tokens", 16, 256, 128, 16)

# Load model based on sidebar selection
pipe = load_model(model_choice)

# Take user input
user_input = st.text_input("Ask me anything:")
go = st.button("Ask")

if go and user_input.strip():
    with st.spinner("Thinking..."):
        if model_choice == "google/flan-t5-small":
            out = pipe(user_input, max_new_tokens=max_new_tokens, do_sample=True)
            st.write("**Bot:**", out[0]["generated_text"])
        else:
            # distilgpt2 uses text-generation task instead of text2text
            gen = pipeline("text-generation", model="distilgpt2")
            out = gen(user_input, max_new_tokens=max_new_tokens, do_sample=True)
            st.write("**Bot:**", out[0]["generated_text"])
